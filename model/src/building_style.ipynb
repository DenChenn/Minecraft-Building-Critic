{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>7</th>\n",
       "      <th>1</th>\n",
       "      <th>4</th>\n",
       "      <th>98</th>\n",
       "      <th>0</th>\n",
       "      <th>3</th>\n",
       "      <th>-48</th>\n",
       "      <th>5</th>\n",
       "      <th>44</th>\n",
       "      <th>...</th>\n",
       "      <th>-22</th>\n",
       "      <th>-78</th>\n",
       "      <th>8</th>\n",
       "      <th>-3</th>\n",
       "      <th>-13</th>\n",
       "      <th>-53</th>\n",
       "      <th>-51</th>\n",
       "      <th>-99</th>\n",
       "      <th>-44</th>\n",
       "      <th>19</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>17667</td>\n",
       "      <td>66956</td>\n",
       "      <td>19754</td>\n",
       "      <td>59458</td>\n",
       "      <td>330777</td>\n",
       "      <td>23900</td>\n",
       "      <td>1246</td>\n",
       "      <td>3360</td>\n",
       "      <td>589</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11238</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>257</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>728</td>\n",
       "      <td>50593</td>\n",
       "      <td>26487</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>117</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10607</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>180</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5586</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>544</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows × 220 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     label      7      1      4     98       0      3   -48     5   44  ...  \\\n",
       "0        0  17667  66956  19754  59458  330777  23900  1246  3360  589  ...   \n",
       "1        0      0      0      0      0   11238      0     0   257    0  ...   \n",
       "2        0      0      0      0    728   50593  26487     0     0  117  ...   \n",
       "3        0      0      6      0      0   10607      0     0     0   21  ...   \n",
       "4        0      0    180      0      0    5586      0     0   544    0  ...   \n",
       "..     ...    ...    ...    ...    ...     ...    ...   ...   ...  ...  ...   \n",
       "395      0      0      0      0      0       0      0     0     0    0  ...   \n",
       "396      0      0      0      0      0       0      0     0     0    0  ...   \n",
       "397      0      0      0      0      0       0      0     0     0    0  ...   \n",
       "398      0      0      0      0      0       0      0     0     0    0  ...   \n",
       "399      0      0      0      0      0       0      0     0     0    0  ...   \n",
       "\n",
       "     -22  -78  8  -3  -13  -53  -51  -99  -44  19  \n",
       "0      0    0  0   0    0    0    0    0    0   0  \n",
       "1      0    0  0   0    0    0    0    0    0   0  \n",
       "2      0    0  0   0    0    0    0    0    0   0  \n",
       "3      0    0  0   0    0    0    0    0    0   0  \n",
       "4      0    0  0   0    0    0    0    0    0   0  \n",
       "..   ...  ... ..  ..  ...  ...  ...  ...  ...  ..  \n",
       "395    0    0  0   0    0    0    0    0    0   0  \n",
       "396    0    0  0   0    0    0    0    0    0   0  \n",
       "397    0    0  0   0    0    0    0    0    0   0  \n",
       "398    0    0  0   0    0    0    0    0    0   0  \n",
       "399    0    0  0   0    0    0    0    0    0   0  \n",
       "\n",
       "[400 rows x 220 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nbtschematic import SchematicFile\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# create python dataframe\n",
    "df = pd.DataFrame(0, index=np.arange(400), columns=[\"label\"])\n",
    "\n",
    "# read all the file\n",
    "ancient_path = '../data/ancient/'\n",
    "modern_path = '../data/modern/'\n",
    "row_index = 0\n",
    "\n",
    "# for ancient building\n",
    "for filename in os.listdir(ancient_path):\n",
    "    if \".schematic\" not in filename:\n",
    "        continue\n",
    "    \n",
    "    sf = SchematicFile.load(ancient_path + filename)\n",
    "    \n",
    "    X = sf.blocks.shape[0]\n",
    "    Y = sf.blocks.shape[1]\n",
    "    Z = sf.blocks.shape[2]\n",
    "    \n",
    "    # counting block\n",
    "    block_record = {}\n",
    "\n",
    "    for i in range(X):\n",
    "        for j in range(Y):\n",
    "            for k in range(Z):\n",
    "                block_id = sf.blocks[i, j, k]\n",
    "                if block_id in block_record.keys():\n",
    "                    block_record[block_id] += 1\n",
    "                else:\n",
    "                    block_record[block_id] = 1\n",
    "    \n",
    "    # insert to dataframe\n",
    "    col_num = len(df.columns)\n",
    "    row_num = 400\n",
    "    \n",
    "    # check whether we need new column\n",
    "    for block_id in block_record:\n",
    "        df.loc[row_index, \"label\"] = 0 #0 represent ancient, 1 represent modern\n",
    "        \n",
    "        block_id = int(block_id)\n",
    "        \n",
    "        if block_id in df.columns:\n",
    "            df.loc[row_index, block_id] = int(block_record[block_id])\n",
    "        else:\n",
    "            df.insert(col_num, block_id, [0 for i in range(row_num)])\n",
    "            col_num += 1\n",
    "            df.loc[row_index, block_id] = int(block_record[block_id])\n",
    "    \n",
    "    row_index += 1\n",
    "    \n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for modern building\n",
    "for filename in os.listdir(modern_path):\n",
    "    if \".schematic\" not in filename:\n",
    "        continue\n",
    "    \n",
    "    sf = SchematicFile.load(modern_path + filename)\n",
    "    \n",
    "    X = sf.blocks.shape[0]\n",
    "    Y = sf.blocks.shape[1]\n",
    "    Z = sf.blocks.shape[2]\n",
    "    \n",
    "    # counting block\n",
    "    block_record = {}\n",
    "\n",
    "    for i in range(X):\n",
    "        for j in range(Y):\n",
    "            for k in range(Z):\n",
    "                block_id = sf.blocks[i, j, k]\n",
    "                if block_id in block_record.keys():\n",
    "                    block_record[block_id] += 1\n",
    "                else:\n",
    "                    block_record[block_id] = 1\n",
    "    \n",
    "    # insert to dataframe\n",
    "    col_num = len(df.columns)\n",
    "    row_num = 400\n",
    "    \n",
    "    # check whether we need new column\n",
    "    for block_id in block_record:\n",
    "        df.loc[row_index, \"label\"] = 1 #0 represent ancient, 1 represent modern\n",
    "        \n",
    "        block_id = int(block_id)\n",
    "        \n",
    "        if block_id in df.columns:\n",
    "            df.loc[row_index, block_id] = int(block_record[block_id])\n",
    "        else:\n",
    "            df.insert(col_num, block_id, [0 for i in range(row_num)])\n",
    "            col_num += 1\n",
    "            df.loc[row_index, block_id] = int(block_record[block_id])\n",
    "    \n",
    "    row_index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>7</th>\n",
       "      <th>1</th>\n",
       "      <th>4</th>\n",
       "      <th>98</th>\n",
       "      <th>0</th>\n",
       "      <th>3</th>\n",
       "      <th>-48</th>\n",
       "      <th>5</th>\n",
       "      <th>44</th>\n",
       "      <th>...</th>\n",
       "      <th>-31</th>\n",
       "      <th>-15</th>\n",
       "      <th>-35</th>\n",
       "      <th>-11</th>\n",
       "      <th>-7</th>\n",
       "      <th>-8</th>\n",
       "      <th>-19</th>\n",
       "      <th>-16</th>\n",
       "      <th>-1</th>\n",
       "      <th>-14</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>17667</td>\n",
       "      <td>66956</td>\n",
       "      <td>19754</td>\n",
       "      <td>59458</td>\n",
       "      <td>330777</td>\n",
       "      <td>23900</td>\n",
       "      <td>1246</td>\n",
       "      <td>3360</td>\n",
       "      <td>589</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11238</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>257</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>728</td>\n",
       "      <td>50593</td>\n",
       "      <td>26487</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>117</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10607</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>180</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5586</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>544</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>762</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50346</td>\n",
       "      <td>14103</td>\n",
       "      <td>0</td>\n",
       "      <td>684</td>\n",
       "      <td>196</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11153</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1311</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>37</td>\n",
       "      <td>144</td>\n",
       "      <td>83</td>\n",
       "      <td>32485</td>\n",
       "      <td>16641</td>\n",
       "      <td>0</td>\n",
       "      <td>967</td>\n",
       "      <td>381</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4804</td>\n",
       "      <td>0</td>\n",
       "      <td>197</td>\n",
       "      <td>119982</td>\n",
       "      <td>6201</td>\n",
       "      <td>0</td>\n",
       "      <td>678</td>\n",
       "      <td>23</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2217</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>29441</td>\n",
       "      <td>9046</td>\n",
       "      <td>0</td>\n",
       "      <td>995</td>\n",
       "      <td>1119</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows × 243 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     label      7      1      4     98       0      3   -48     5    44  ...  \\\n",
       "0        0  17667  66956  19754  59458  330777  23900  1246  3360   589  ...   \n",
       "1        0      0      0      0      0   11238      0     0   257     0  ...   \n",
       "2        0      0      0      0    728   50593  26487     0     0   117  ...   \n",
       "3        0      0      6      0      0   10607      0     0     0    21  ...   \n",
       "4        0      0    180      0      0    5586      0     0   544     0  ...   \n",
       "..     ...    ...    ...    ...    ...     ...    ...   ...   ...   ...  ...   \n",
       "395      1     12    762      0      0   50346  14103     0   684   196  ...   \n",
       "396      1      0      0      0      0   11153      0     0     0  1311  ...   \n",
       "397      1      0     37    144     83   32485  16641     0   967   381  ...   \n",
       "398      1      0   4804      0    197  119982   6201     0   678    23  ...   \n",
       "399      1      0   2217      0      0   29441   9046     0   995  1119  ...   \n",
       "\n",
       "     -31  -15  -35  -11  -7  -8  -19  -16  -1  -14  \n",
       "0      0    0    0    0   0   0    0    0   0    0  \n",
       "1      0    0    0    0   0   0    0    0   0    0  \n",
       "2      0    0    0    0   0   0    0    0   0    0  \n",
       "3      0    0    0    0   0   0    0    0   0    0  \n",
       "4      0    0    0    0   0   0    0    0   0    0  \n",
       "..   ...  ...  ...  ...  ..  ..  ...  ...  ..  ...  \n",
       "395    0    0    0    0   0   0    0    0   0    0  \n",
       "396    0    0    0    0   0   0    0    0   0    0  \n",
       "397    0    0    0    0   0   0    0    0   0    0  \n",
       "398    0    0    0    0   0   0    0    0   0    0  \n",
       "399    0    0    0    0   0   0    0    0   0    0  \n",
       "\n",
       "[400 rows x 243 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 計算哪一種建材對於兩個 label 的差值最大，造成最大的影響\n",
    "D = {}\n",
    "\n",
    "for col in df.columns:\n",
    "    label0_mean = 0\n",
    "    for index_of_label0 in range(200):\n",
    "        label0_mean += df.loc[index_of_label0, col]\n",
    "    label0_mean = label0_mean / 200\n",
    "    \n",
    "    label1_mean = 0\n",
    "    for index_of_label1 in range(200, 400):\n",
    "        label1_mean += df.loc[index_of_label1, col]\n",
    "    label1_mean = label1_mean / 200\n",
    "    \n",
    "    D[col] = abs(label0_mean - label1_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "\n",
    "# Plot the data distribution by value count of their labels (targets)\n",
    "def beautiful_plot(X, Y, x_label, y_label, title):\n",
    "    x = np.arange(len(X))\n",
    "    y = Y\n",
    "    \n",
    "    plt.figure(figsize=(10,10))\n",
    "    cmap = cm.jet(np.linspace(0, 1, len(X)))\n",
    "    plt.barh(x, y, edgecolor = 'gray', alpha=0.6, color=cmap)\n",
    "    plt.yticks(x, X)\n",
    "    plt.xlabel(x_label)\n",
    "    plt.ylabel(y_label)\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "\n",
    "s = sorted(D.items(), key=lambda item: item[1], reverse=True)[:10]\n",
    "x_list = [k for k, _ in s]\n",
    "y_list = [v for _, v in s]\n",
    "beautiful_plot(x_list, y_list, 'differ', 'Feature', 'Top 10 Features')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>7</th>\n",
       "      <th>1</th>\n",
       "      <th>4</th>\n",
       "      <th>98</th>\n",
       "      <th>3</th>\n",
       "      <th>-48</th>\n",
       "      <th>5</th>\n",
       "      <th>44</th>\n",
       "      <th>-63</th>\n",
       "      <th>109</th>\n",
       "      <th>...</th>\n",
       "      <th>-31</th>\n",
       "      <th>-15</th>\n",
       "      <th>-35</th>\n",
       "      <th>-11</th>\n",
       "      <th>-7</th>\n",
       "      <th>-8</th>\n",
       "      <th>-19</th>\n",
       "      <th>-16</th>\n",
       "      <th>-1</th>\n",
       "      <th>-14</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0</td>\n",
       "      <td>51</td>\n",
       "      <td>0</td>\n",
       "      <td>145</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>78</td>\n",
       "      <td>86</td>\n",
       "      <td>0</td>\n",
       "      <td>66</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361</th>\n",
       "      <td>0</td>\n",
       "      <td>4249</td>\n",
       "      <td>201</td>\n",
       "      <td>347</td>\n",
       "      <td>3394</td>\n",
       "      <td>0</td>\n",
       "      <td>1279</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>163</td>\n",
       "      <td>0</td>\n",
       "      <td>114</td>\n",
       "      <td>53</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>365</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "      <td>324</td>\n",
       "      <td>66</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8996</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>224</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>980</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>82</td>\n",
       "      <td>0</td>\n",
       "      <td>492</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>366</th>\n",
       "      <td>0</td>\n",
       "      <td>466</td>\n",
       "      <td>46</td>\n",
       "      <td>47</td>\n",
       "      <td>158</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>75</td>\n",
       "      <td>0</td>\n",
       "      <td>134</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1475</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>49</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1087</td>\n",
       "      <td>0</td>\n",
       "      <td>503</td>\n",
       "      <td>348</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>88</td>\n",
       "      <td>0</td>\n",
       "      <td>424</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows × 241 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      7     1     4     98    3    -48    5     44   -63    109  ...  -31   \\\n",
       "46      0    51     0   145     0     0    78    86     0    66  ...     0   \n",
       "361     0  4249   201   347  3394     0  1279    32     0     5  ...     0   \n",
       "393     0     0     0     0   163     0   114    53     0     0  ...     0   \n",
       "365     0     0     0     0    56     0   324    66     0     0  ...     0   \n",
       "43      2     0     0     0  8996     0     0   224     0     0  ...     0   \n",
       "..    ...   ...   ...   ...   ...   ...   ...   ...   ...   ...  ...   ...   \n",
       "32      0     0     0   980     0     0     0    82     0   492  ...     0   \n",
       "366     0   466    46    47   158     0     0    75     0   134  ...     0   \n",
       "268     0     0     0  1475     5     0    49    15     0     0  ...     0   \n",
       "286     0     1     0     0  1087     0   503   348     0     0  ...     0   \n",
       "292     0     0     0     0    88     0   424     0     0     0  ...     0   \n",
       "\n",
       "     -15   -35   -11   -7    -8    -19   -16   -1    -14   \n",
       "46      0     0     0     0     0     0     0     0     0  \n",
       "361     0     0     0     0     0     0     0     0     0  \n",
       "393     0     0     0     0     0     0     0     0     0  \n",
       "365     0     0     0     0     0     0     0     0     0  \n",
       "43      0     0     0     0     0     0     0     0     0  \n",
       "..    ...   ...   ...   ...   ...   ...   ...   ...   ...  \n",
       "32      0     0     0     0     0     0     0     0     0  \n",
       "366     0     0     0     0     0     0     0     0     0  \n",
       "268     0     0     0     0     0     0     0     0     0  \n",
       "286     0     0     0     0     0     0     0     0     0  \n",
       "292     0     0     0     0     0     0     0     0     0  \n",
       "\n",
       "[400 rows x 241 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.utils import shuffle\n",
    "\n",
    "# shuffle the data\n",
    "sample_df = df.copy()\n",
    "sample_df = shuffle(sample_df)\n",
    "target = np.array(sample_df[\"label\"])\n",
    "sample_df = sample_df.drop(\"label\", 1)\n",
    "\n",
    "# block id 0 represent air block, we are not going to consider about it\n",
    "sample_df = sample_df.drop(0, 1)\n",
    "\n",
    "sample_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "from torch.autograd import Variable\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# traing-test-split 7:3\n",
    "training_sample, testing_sample, training_target, testing_target = train_test_split(sample_df, target, test_size = 0.3) \n",
    "\n",
    "# transfer to numpy array\n",
    "x_training_sample = training_sample.to_numpy()\n",
    "x_testing_sample = testing_sample.to_numpy()\n",
    "\n",
    "# to pytorch numpy\n",
    "T_training_sample = torch.FloatTensor(x_training_sample)\n",
    "T_training_target = torch.LongTensor(training_target).type(torch.LongTensor)\n",
    "\n",
    "T_testing_sample = torch.FloatTensor(x_testing_sample)\n",
    "T_testing_target = torch.LongTensor(testing_target).type(torch.LongTensor)\n",
    "\n",
    "# Pytorch train and test sets\n",
    "train = torch.utils.data.TensorDataset(T_training_sample, T_training_target)\n",
    "test = torch.utils.data.TensorDataset(T_testing_sample, T_testing_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Construction 1 : ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ANNModel(nn.Module):\n",
    "    def __init__(self, input_features, hidden_layer1, output_features):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(input_features, hidden_layer1) \n",
    "        self.Sigmoid1 = nn.Sigmoid()\n",
    "        self.fc2 = nn.Linear(hidden_layer1, output_features)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.Sigmoid1(out)\n",
    "        out = self.fc2(out)\n",
    "\n",
    "        return out\n",
    "    \n",
    "\n",
    "input_feature = len(sample_df.columns)\n",
    "hidden_layer1 = 500\n",
    "output_features = 2 # number of type of target\n",
    "\n",
    "# Create ANN\n",
    "model = ANNModel(input_feature, hidden_layer1, output_features)\n",
    "\n",
    "# Cross Entropy Loss \n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training 1 : ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  0  loss: 0.85589767\n",
      "Accuracy: 0.475\n",
      "epoch:  1  loss: 1.82788479\n",
      "Accuracy: 0.6166666666666667\n",
      "epoch:  2  loss: 0.60115498\n",
      "Accuracy: 0.85\n",
      "epoch:  3  loss: 0.29691017\n",
      "Accuracy: 0.7916666666666666\n",
      "epoch:  4  loss: 0.50763983\n",
      "Accuracy: 0.7833333333333333\n",
      "epoch:  5  loss: 0.53508079\n",
      "Accuracy: 0.8333333333333334\n",
      "epoch:  6  loss: 0.41685456\n",
      "Accuracy: 0.85\n",
      "epoch:  7  loss: 0.29336321\n",
      "Accuracy: 0.8833333333333333\n",
      "epoch:  8  loss: 0.22278899\n",
      "Accuracy: 0.875\n",
      "epoch:  9  loss: 0.21485010\n",
      "Accuracy: 0.8583333333333333\n",
      "epoch: 10  loss: 0.24757336\n",
      "Accuracy: 0.825\n",
      "epoch: 11  loss: 0.27351561\n",
      "Accuracy: 0.8083333333333333\n",
      "epoch: 12  loss: 0.27591008\n",
      "Accuracy: 0.85\n",
      "epoch: 13  loss: 0.25026536\n",
      "Accuracy: 0.8666666666666667\n",
      "epoch: 14  loss: 0.21779943\n",
      "Accuracy: 0.8583333333333333\n",
      "epoch: 15  loss: 0.19111818\n",
      "Accuracy: 0.8916666666666667\n",
      "epoch: 16  loss: 0.17901844\n",
      "Accuracy: 0.9\n",
      "epoch: 17  loss: 0.17752713\n",
      "Accuracy: 0.8833333333333333\n",
      "epoch: 18  loss: 0.18093403\n",
      "Accuracy: 0.9\n",
      "epoch: 19  loss: 0.18462917\n",
      "Accuracy: 0.9\n",
      "epoch: 20  loss: 0.18506636\n",
      "Accuracy: 0.9\n",
      "epoch: 21  loss: 0.17477028\n",
      "Accuracy: 0.9166666666666666\n",
      "epoch: 22  loss: 0.16175215\n",
      "Accuracy: 0.9166666666666666\n",
      "epoch: 23  loss: 0.14876477\n",
      "Accuracy: 0.9166666666666666\n",
      "epoch: 24  loss: 0.13975058\n",
      "Accuracy: 0.9083333333333333\n",
      "epoch: 25  loss: 0.13863072\n",
      "Accuracy: 0.8916666666666667\n",
      "epoch: 26  loss: 0.13844411\n",
      "Accuracy: 0.8833333333333333\n",
      "epoch: 27  loss: 0.14105597\n",
      "Accuracy: 0.8833333333333333\n",
      "epoch: 28  loss: 0.14012025\n",
      "Accuracy: 0.875\n",
      "epoch: 29  loss: 0.13649827\n",
      "Accuracy: 0.8916666666666667\n",
      "epoch: 30  loss: 0.13055722\n",
      "Accuracy: 0.9166666666666666\n",
      "epoch: 31  loss: 0.12782983\n",
      "Accuracy: 0.9166666666666666\n",
      "epoch: 32  loss: 0.12485693\n",
      "Accuracy: 0.9166666666666666\n",
      "epoch: 33  loss: 0.12244873\n",
      "Accuracy: 0.9166666666666666\n",
      "epoch: 34  loss: 0.12297735\n",
      "Accuracy: 0.925\n",
      "epoch: 35  loss: 0.12071333\n",
      "Accuracy: 0.925\n",
      "epoch: 36  loss: 0.11965661\n",
      "Accuracy: 0.9166666666666666\n",
      "epoch: 37  loss: 0.11662383\n",
      "Accuracy: 0.925\n",
      "epoch: 38  loss: 0.11193064\n",
      "Accuracy: 0.9333333333333333\n",
      "epoch: 39  loss: 0.10852873\n",
      "Accuracy: 0.9166666666666666\n",
      "epoch: 40  loss: 0.10665514\n",
      "Accuracy: 0.9083333333333333\n",
      "epoch: 41  loss: 0.10675047\n",
      "Accuracy: 0.9083333333333333\n",
      "epoch: 42  loss: 0.10577304\n",
      "Accuracy: 0.9\n",
      "epoch: 43  loss: 0.10533325\n",
      "Accuracy: 0.9\n",
      "epoch: 44  loss: 0.10223268\n",
      "Accuracy: 0.8916666666666667\n",
      "epoch: 45  loss: 0.09967355\n",
      "Accuracy: 0.9\n",
      "epoch: 46  loss: 0.09867806\n",
      "Accuracy: 0.8916666666666667\n",
      "epoch: 47  loss: 0.09638432\n",
      "Accuracy: 0.8916666666666667\n",
      "epoch: 48  loss: 0.09567931\n",
      "Accuracy: 0.8916666666666667\n",
      "epoch: 49  loss: 0.09411490\n",
      "Accuracy: 0.8833333333333333\n",
      "epoch: 50  loss: 0.08922534\n",
      "Accuracy: 0.8833333333333333\n",
      "epoch: 51  loss: 0.08611097\n",
      "Accuracy: 0.8833333333333333\n",
      "epoch: 52  loss: 0.08572559\n",
      "Accuracy: 0.8833333333333333\n",
      "epoch: 53  loss: 0.08469439\n",
      "Accuracy: 0.8833333333333333\n",
      "epoch: 54  loss: 0.08465748\n",
      "Accuracy: 0.8833333333333333\n",
      "epoch: 55  loss: 0.08904265\n",
      "Accuracy: 0.8833333333333333\n",
      "epoch: 56  loss: 0.08893739\n",
      "Accuracy: 0.8916666666666667\n",
      "epoch: 57  loss: 0.08830053\n",
      "Accuracy: 0.9\n",
      "epoch: 58  loss: 0.08951005\n",
      "Accuracy: 0.9\n",
      "epoch: 59  loss: 0.08806495\n",
      "Accuracy: 0.9\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score, recall_score, precision_score\n",
    "\n",
    "# ANN model training\n",
    "count = 0\n",
    "loss_list = []\n",
    "iteration_list = []\n",
    "accuracy_list = []\n",
    "epochs = 60\n",
    "\n",
    "for i in range(epochs):\n",
    "    pred = model.forward(T_training_sample)\n",
    "    \n",
    "    optimizer.zero_grad() # Clear gradients\n",
    "    loss = criterion(pred, T_training_target)\n",
    "    loss_list.append(loss)\n",
    "    loss.backward() # Calculating gradients\n",
    "    optimizer.step() # Update parameters\n",
    "    \n",
    "\n",
    "    print(f'epoch: {i:2}  loss: {loss.item():10.8f}')\n",
    "    preds = []\n",
    "    with torch.no_grad():\n",
    "        for val in T_testing_sample:\n",
    "            y_hat = model.forward(val)\n",
    "            preds.append(y_hat.argmax().item())\n",
    "    acc = accuracy_score(testing_target, preds)\n",
    "    print(\"Accuracy: {}\".format(acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Result Print : ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+----------+--------------------+--------------------+\n",
      "| Confusion Matrix | Accuracy |       Recall       |     Precision      |\n",
      "+------------------+----------+--------------------+--------------------+\n",
      "|     [[52  5]     |   0.9    | 0.9005847953216374 | 0.8996943595443179 |\n",
      "|     [ 7 56]]     |          |                    |                    |\n",
      "+------------------+----------+--------------------+--------------------+\n"
     ]
    }
   ],
   "source": [
    "from prettytable import PrettyTable\n",
    "\n",
    "# Predict the result with our model\n",
    "preds = []\n",
    "with torch.no_grad():\n",
    "    for val in T_testing_sample:\n",
    "        y_hat = model.forward(val)\n",
    "        preds.append(y_hat.argmax().item())\n",
    "        \n",
    "acc = accuracy_score(testing_target, preds)\n",
    "cm = confusion_matrix(testing_target, preds)\n",
    "rc = recall_score(testing_target, preds, average='macro')\n",
    "pcs = precision_score(testing_target, preds, average='macro')\n",
    "\n",
    "# print table\n",
    "x = PrettyTable()\n",
    "\n",
    "x.field_names = [\"Confusion Matrix\", \"Accuracy\", \"Recall\", \"Precision\"]\n",
    "x.add_row([cm, acc, rc, pcs])\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Construction : Decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "def decision_tree_clf(training_sample, training_target, testing_sample, testing_target):\n",
    "    clf = DecisionTreeClassifier()\n",
    "    \n",
    "    predict_list = []\n",
    "    \n",
    "    clf.fit(training_sample, training_target)\n",
    "    predict_list = clf.predict(testing_sample)\n",
    "    \n",
    "    result_list = []\n",
    "    result_list.append(confusion_matrix(testing_target, predict_list))\n",
    "    result_list.append(accuracy_score(testing_target, predict_list))\n",
    "    result_list.append(recall_score(testing_target, predict_list, average='macro'))\n",
    "    result_list.append(precision_score(testing_target, predict_list, average='macro'))\n",
    "    return result_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Result Print : Decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+--------------------+--------------------+--------------------+\n",
      "| Confusion Matrix |      Accuracy      |       Recall       |     Precision      |\n",
      "+------------------+--------------------+--------------------+--------------------+\n",
      "|     [[43 14]     | 0.7666666666666667 | 0.7660818713450293 | 0.7660818713450293 |\n",
      "|     [14 49]]     |                    |                    |                    |\n",
      "+------------------+--------------------+--------------------+--------------------+\n"
     ]
    }
   ],
   "source": [
    "result = decision_tree_clf(training_sample, training_target, testing_sample, testing_target)\n",
    "\n",
    "x = PrettyTable()\n",
    "\n",
    "x.field_names = [\"Confusion Matrix\", \"Accuracy\", \"Recall\", \"Precision\"]\n",
    "x.add_row([result[0], result[1], result[2], result[3]])\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Construction 3 : Quantum ML model with Variational classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# relabeling data\n",
    "\n",
    "quantum_df = df.copy()\n",
    "quantum_df = shuffle(quantum_df)\n",
    "\n",
    "for index, row in quantum_df.iterrows():\n",
    "    if quantum_df.loc[index, 'label'] == 0:\n",
    "        quantum_df.loc[index, 'label'] = -1\n",
    "        \n",
    "target = np.array(quantum_df[\"label\"])\n",
    "quantum_df = quantum_df.drop(\"label\", 1)\n",
    "\n",
    "# block id 0 represent air block, we are not going to consider about it\n",
    "quantum_df = quantum_df.drop(0, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pennylane as qml\n",
    "from pennylane import numpy as qnp\n",
    "from pennylane.optimize import NesterovMomentumOptimizer\n",
    "\n",
    "dev = qml.device(\"default.qubit\", wires=4)\n",
    "\n",
    "def get_angles(x):\n",
    "\n",
    "    beta0 = 2 * qnp.arcsin(qnp.sqrt(x[1] ** 2) / qnp.sqrt(x[0] ** 2 + x[1] ** 2 + 1e-12))\n",
    "    beta1 = 2 * qnp.arcsin(qnp.sqrt(x[3] ** 2) / qnp.sqrt(x[2] ** 2 + x[3] ** 2 + 1e-12))\n",
    "    beta2 = 2 * qnp.arcsin(\n",
    "        qnp.sqrt(x[2] ** 2 + x[3] ** 2)\n",
    "        / qnp.sqrt(x[0] ** 2 + x[1] ** 2 + x[2] ** 2 + x[3] ** 2)\n",
    "    )\n",
    "\n",
    "    return qnp.array([beta2, -beta1 / 2, beta1 / 2, -beta0 / 2, beta0 / 2])\n",
    "\n",
    "\n",
    "def statepreparation(a):\n",
    "    qml.RY(a[0], wires=0)\n",
    "\n",
    "    qml.CNOT(wires=[0, 1])\n",
    "    qml.RY(a[1], wires=1)\n",
    "    qml.CNOT(wires=[0, 1])\n",
    "    qml.RY(a[2], wires=1)\n",
    "\n",
    "    qml.PauliX(wires=0)\n",
    "    qml.CNOT(wires=[0, 1])\n",
    "    qml.RY(a[3], wires=1)\n",
    "    qml.CNOT(wires=[0, 1])\n",
    "    qml.RY(a[4], wires=1)\n",
    "    qml.PauliX(wires=0)\n",
    "\n",
    "def layer(W):\n",
    "    qml.Rot(W[0, 0], W[0, 1], W[0, 2], wires=0)\n",
    "    qml.Rot(W[1, 0], W[1, 1], W[1, 2], wires=1)\n",
    "    qml.CNOT(wires=[0, 1])\n",
    "\n",
    "@qml.qnode(dev)\n",
    "def circuit(weights, angles):\n",
    "    statepreparation(angles)\n",
    "\n",
    "    for W in weights:\n",
    "        layer(W)\n",
    "\n",
    "    return qml.expval(qml.PauliZ(0))\n",
    "\n",
    "\n",
    "def variational_classifier(weights, bias, angles):\n",
    "    return circuit(weights, angles) + bias\n",
    "\n",
    "def square_loss(labels, predictions):\n",
    "    loss = 0\n",
    "    for l, p in zip(labels, predictions):\n",
    "        loss = loss + (l - p) ** 2\n",
    "\n",
    "    loss = loss / len(labels)\n",
    "    return loss\n",
    "\n",
    "def accuracy(labels, predictions):\n",
    "\n",
    "    loss = 0\n",
    "    for l, p in zip(labels, predictions):\n",
    "        if abs(l - p) < 1e-5:\n",
    "            loss = loss + 1\n",
    "    loss = loss / len(labels)\n",
    "\n",
    "    return loss\n",
    "\n",
    "def cost(weights, bias, features, labels):\n",
    "    predictions = [variational_classifier(weights, bias, f) for f in features]\n",
    "    return square_loss(labels, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(400, 2)\n",
      "First X sample (original)  : [    0 14693]\n",
      "First X sample (padded)    : [0.0000e+00 1.4693e+04 3.0000e-01 0.0000e+00]\n",
      "First X sample (normalized): [0.00000000e+00 1.00000000e+00 2.04178861e-05 0.00000000e+00]\n",
      "First features sample      : [ 4.08357721e-05 -0.00000000e+00  0.00000000e+00 -1.57079533e+00\n",
      "  1.57079533e+00]\n"
     ]
    }
   ],
   "source": [
    "X = qnp.array(np.transpose(np.array([quantum_df[24].to_numpy(), quantum_df[1].to_numpy()])))\n",
    "print(X.shape)\n",
    "print(\"First X sample (original)  :\", X[0])\n",
    "\n",
    "# pad the vectors to size 2^2 with constant values\n",
    "padding = 0.3 * qnp.ones((len(X), 1))\n",
    "X_pad = qnp.c_[qnp.c_[X, padding], qnp.zeros((len(X), 1))]\n",
    "print(\"First X sample (padded)    :\", X_pad[0])\n",
    "\n",
    "# normalize each input\n",
    "normalization = qnp.sqrt(qnp.sum(X_pad ** 2, -1))\n",
    "X_norm = (X_pad.T / normalization).T\n",
    "print(\"First X sample (normalized):\", X_norm[0])\n",
    "\n",
    "# angles for state preparation are new features\n",
    "features = qnp.array([get_angles(x) for x in X_norm], requires_grad=False)\n",
    "print(\"First features sample      :\", features[0])\n",
    "\n",
    "Y = qnp.array(target)\n",
    "\n",
    "qnp.random.seed(0)\n",
    "num_data = len(Y)\n",
    "num_train = int(0.75 * num_data)\n",
    "index = qnp.random.permutation(range(num_data))\n",
    "feats_train = features[index[:num_train]]\n",
    "Y_train = Y[index[:num_train]]\n",
    "feats_val = features[index[num_train:]]\n",
    "Y_val = Y[index[num_train:]]\n",
    "\n",
    "# We need these later for plotting\n",
    "X_train = X[index[:num_train]]\n",
    "X_val = X[index[num_train:]]\n",
    "\n",
    "num_qubits = 2\n",
    "num_layers = 6\n",
    "\n",
    "weights_init = 0.01 * qnp.random.randn(num_layers, num_qubits, 3, requires_grad=True)\n",
    "bias_init = qnp.array(0.0, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter:     1 | Cost: 1.9795278 | Acc validation: 0.5000000 \n",
      "Iter:     2 | Cost: 1.9795114 | Acc validation: 0.5000000 \n",
      "Iter:     3 | Cost: 1.9791301 | Acc validation: 0.5000000 \n",
      "Iter:     4 | Cost: 1.9788216 | Acc validation: 0.5000000 \n",
      "Iter:     5 | Cost: 1.9785401 | Acc validation: 0.5000000 \n",
      "Iter:     6 | Cost: 1.9782763 | Acc validation: 0.5000000 \n",
      "Iter:     7 | Cost: 1.9773279 | Acc validation: 0.5000000 \n",
      "Iter:     8 | Cost: 1.9768304 | Acc validation: 0.5000000 \n",
      "Iter:     9 | Cost: 1.9763893 | Acc validation: 0.5000000 \n",
      "Iter:    10 | Cost: 1.9749300 | Acc validation: 0.5000000 \n",
      "Iter:    11 | Cost: 1.9725917 | Acc validation: 0.5000000 \n",
      "Iter:    12 | Cost: 1.9698728 | Acc validation: 0.5000000 \n",
      "Iter:    13 | Cost: 1.9662136 | Acc validation: 0.5000000 \n",
      "Iter:    14 | Cost: 1.9630655 | Acc validation: 0.5000000 \n",
      "Iter:    15 | Cost: 1.9594751 | Acc validation: 0.5000000 \n",
      "Iter:    16 | Cost: 1.9561330 | Acc validation: 0.5000000 \n",
      "Iter:    17 | Cost: 1.9522413 | Acc validation: 0.5000000 \n",
      "Iter:    18 | Cost: 1.9494627 | Acc validation: 0.5000000 \n",
      "Iter:    19 | Cost: 1.9466475 | Acc validation: 0.5000000 \n",
      "Iter:    20 | Cost: 1.9442549 | Acc validation: 0.5000000 \n",
      "Iter:    21 | Cost: 1.9420354 | Acc validation: 0.5000000 \n",
      "Iter:    22 | Cost: 1.9405211 | Acc validation: 0.5000000 \n",
      "Iter:    23 | Cost: 1.9388175 | Acc validation: 0.5000000 \n",
      "Iter:    24 | Cost: 1.9368196 | Acc validation: 0.5000000 \n",
      "Iter:    25 | Cost: 1.9351648 | Acc validation: 0.5000000 \n",
      "Iter:    26 | Cost: 1.9340619 | Acc validation: 0.5000000 \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-e1d22a9c96f5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m     print(\n\u001b[1;32m     24\u001b[0m         \u001b[0;34m\"Iter: {:5d} | Cost: {:0.7f} | Acc validation: {:0.7f} \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0;34m\"\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mit\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcost\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m     )\n",
      "\u001b[0;32m<ipython-input-17-d14dcd621bbf>\u001b[0m in \u001b[0;36mcost\u001b[0;34m(weights, bias, features, labels)\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcost\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m     \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mvariational_classifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0msquare_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-17-d14dcd621bbf>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcost\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m     \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mvariational_classifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0msquare_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-17-d14dcd621bbf>\u001b[0m in \u001b[0;36mvariational_classifier\u001b[0;34m(weights, bias, angles)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mvariational_classifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mangles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcircuit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mangles\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msquare_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pennylane/qnode.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    559\u001b[0m         \u001b[0mtapes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprocessing_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 561\u001b[0;31m         res = qml.execute(\n\u001b[0m\u001b[1;32m    562\u001b[0m             \u001b[0mtapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m             \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pennylane/interfaces/batch/__init__.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(tapes, device, gradient_fn, interface, mode, gradient_kwargs, cache, cachesize, max_diff, override_shots, expand_fn, max_expansion)\u001b[0m\n\u001b[1;32m    319\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mgradient_fn\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"backprop\"\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0minterface\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 321\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcache_execute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_execute\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_tuple\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpand_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexpand_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtapes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    322\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m     \u001b[0;31m# the default execution function is batch_execute\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pennylane/interfaces/batch/__init__.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(tapes, **kwargs)\u001b[0m\n\u001b[1;32m    166\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m             \u001b[0;31m# execute all unique tapes that do not exist in the cache\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 168\u001b[0;31m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexecution_tapes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    169\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m         \u001b[0mfinal_res\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pennylane/interfaces/batch/__init__.py\u001b[0m in \u001b[0;36mfn\u001b[0;34m(tapes, **kwargs)\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtapes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=function-redefined\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0mtapes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mexpand_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtape\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtapes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0moriginal_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtapes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/contextlib.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_recreate_cm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pennylane/_qubit_device.py\u001b[0m in \u001b[0;36mbatch_execute\u001b[0;34m(self, circuits)\u001b[0m\n\u001b[1;32m    276\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 278\u001b[0;31m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcircuit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    279\u001b[0m             \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pennylane/_qubit_device.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, circuit, **kwargs)\u001b[0m\n\u001b[1;32m    192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m         \u001b[0;31m# apply all circuit operations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 194\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcircuit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moperations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrotations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcircuit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiagonalizing_gates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m         \u001b[0;31m# generate computational basis samples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pennylane/devices/default_qubit.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, operations, rotations, **kwargs)\u001b[0m\n\u001b[1;32m    214\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply_basis_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moperation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moperation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwires\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply_operation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moperation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m         \u001b[0;31m# store the pre-rotated state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pennylane/devices/default_qubit.py\u001b[0m in \u001b[0;36m_apply_operation\u001b[0;34m(self, state, operation)\u001b[0m\n\u001b[1;32m    239\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply_ops\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0moperation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minverse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moperation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minverse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 241\u001b[0;31m         \u001b[0mmatrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_unitary_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moperation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    242\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0moperation\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdiagonal_in_z_basis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pennylane/devices/default_qubit.py\u001b[0m in \u001b[0;36m_get_unitary_matrix\u001b[0;34m(self, unitary)\u001b[0m\n\u001b[1;32m    546\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0munitary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meigvals\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 548\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0munitary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    549\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pennylane/operation.py\u001b[0m in \u001b[0;36mmatrix\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    779\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    780\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 781\u001b[0;31m         \u001b[0mop_matrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    782\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    783\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minverse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pennylane/ops/qubit/parametric_ops.py\u001b[0m in \u001b[0;36m_matrix\u001b[0;34m(cls, *params)\u001b[0m\n\u001b[1;32m    411\u001b[0m             [\n\u001b[1;32m    412\u001b[0m                 \u001b[0mqml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m0.5j\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mphi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0momega\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 413\u001b[0;31m                 \u001b[0;34m-\u001b[0m\u001b[0mqml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.5j\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mphi\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0momega\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    414\u001b[0m             ],\n\u001b[1;32m    415\u001b[0m             [\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/autoray/autoray.py\u001b[0m in \u001b[0;36mdo\u001b[0;34m(fn, like, *args, **kwargs)\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0mbackend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minfer_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlike\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mget_lib_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbackend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pennylane/numpy/tensor.py\u001b[0m in \u001b[0;36m__array_ufunc__\u001b[0;34m(self, ufunc, method, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    172\u001b[0m         \u001b[0;31m# We also correctly set the requires_grad attribute.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mufunc_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=consider-using-enumerate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 174\u001b[0;31m             \u001b[0mufunc_output\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mufunc_output\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequires_grad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequires_grad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    175\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mufunc_output\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pennylane/numpy/tensor.py\u001b[0m in \u001b[0;36m__new__\u001b[0;34m(cls, input_array, requires_grad, *args, **kwargs)\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__new__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_array\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequires_grad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m         \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_array\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0monp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/autograd/tracer.py\u001b[0m in \u001b[0;36mf_wrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mnew_box\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mans\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf_raw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m     \u001b[0mf_wrapped\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfun\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf_raw\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0mf_wrapped\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_autograd_primitive\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pennylane/numpy/tensor.py\u001b[0m in \u001b[0;36masarray\u001b[0;34m(vals, *args, **kwargs)\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0;34m\"\"\"Gradient supporting autograd asarray\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0monp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_np\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_np\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_np\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/autograd/tracer.py\u001b[0m in \u001b[0;36mf_wrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf_raw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mf_wrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m         \u001b[0mboxed_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode_constructor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_top_boxed_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mboxed_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m             \u001b[0margvals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msubvals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margnum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbox\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0margnum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbox\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mboxed_args\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/autograd/tracer.py\u001b[0m in \u001b[0;36mfind_top_boxed_args\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0mtop_boxes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0mtop_node_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0margnum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misbox\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m             \u001b[0mtrace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_trace\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "opt = NesterovMomentumOptimizer(0.001)\n",
    "batch_size = 5\n",
    "\n",
    "# train the variational classifier\n",
    "weights = weights_init\n",
    "bias = bias_init\n",
    "\n",
    "for it in range(60):\n",
    "    # Update the weights by one optimizer step\n",
    "    batch_index = qnp.random.randint(0, num_train, (batch_size,))\n",
    "    feats_train_batch = feats_train[batch_index]\n",
    "    Y_train_batch = Y_train[batch_index]\n",
    "    weights, bias, _, _ = opt.step(cost, weights, bias, feats_train_batch, Y_train_batch)\n",
    "\n",
    "    # Compute predictions on train and validation set\n",
    "    predictions_train = [qnp.sign(variational_classifier(weights, bias, f)) for f in feats_train]\n",
    "    predictions_val = [qnp.sign(variational_classifier(weights, bias, f)) for f in feats_val]\n",
    "\n",
    "    # Compute accuracy on train and validation set\n",
    "    acc_train = accuracy(Y_train, predictions_train)\n",
    "    acc_val = accuracy(Y_val, predictions_val)\n",
    "\n",
    "    print(\n",
    "        \"Iter: {:5d} | Cost: {:0.7f} | Acc validation: {:0.7f} \"\n",
    "        \"\".format(it + 1, cost(weights, bias, features, Y), acc_val)\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
