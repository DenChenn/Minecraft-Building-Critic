{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b205ee77-d557-4e56-8ad6-c88cf48836ba",
   "metadata": {},
   "source": [
    "### Data input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "db6e0068-6cfe-4a62-998f-3caaa6c8e302",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>7</th>\n",
       "      <th>1</th>\n",
       "      <th>4</th>\n",
       "      <th>98</th>\n",
       "      <th>0</th>\n",
       "      <th>3</th>\n",
       "      <th>-48</th>\n",
       "      <th>5</th>\n",
       "      <th>44</th>\n",
       "      <th>...</th>\n",
       "      <th>-22</th>\n",
       "      <th>-78</th>\n",
       "      <th>8</th>\n",
       "      <th>-3</th>\n",
       "      <th>-13</th>\n",
       "      <th>-53</th>\n",
       "      <th>-51</th>\n",
       "      <th>-99</th>\n",
       "      <th>-44</th>\n",
       "      <th>19</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>17667</td>\n",
       "      <td>66956</td>\n",
       "      <td>19754</td>\n",
       "      <td>59458</td>\n",
       "      <td>330777</td>\n",
       "      <td>23900</td>\n",
       "      <td>1246</td>\n",
       "      <td>3360</td>\n",
       "      <td>589</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11238</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>257</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>728</td>\n",
       "      <td>50593</td>\n",
       "      <td>26487</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>117</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10607</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>180</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5586</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>544</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows × 220 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     label      7      1      4     98       0      3   -48     5   44  ...  \\\n",
       "0        0  17667  66956  19754  59458  330777  23900  1246  3360  589  ...   \n",
       "1        0      0      0      0      0   11238      0     0   257    0  ...   \n",
       "2        0      0      0      0    728   50593  26487     0     0  117  ...   \n",
       "3        0      0      6      0      0   10607      0     0     0   21  ...   \n",
       "4        0      0    180      0      0    5586      0     0   544    0  ...   \n",
       "..     ...    ...    ...    ...    ...     ...    ...   ...   ...  ...  ...   \n",
       "395      0      0      0      0      0       0      0     0     0    0  ...   \n",
       "396      0      0      0      0      0       0      0     0     0    0  ...   \n",
       "397      0      0      0      0      0       0      0     0     0    0  ...   \n",
       "398      0      0      0      0      0       0      0     0     0    0  ...   \n",
       "399      0      0      0      0      0       0      0     0     0    0  ...   \n",
       "\n",
       "     -22  -78  8  -3  -13  -53  -51  -99  -44  19  \n",
       "0      0    0  0   0    0    0    0    0    0   0  \n",
       "1      0    0  0   0    0    0    0    0    0   0  \n",
       "2      0    0  0   0    0    0    0    0    0   0  \n",
       "3      0    0  0   0    0    0    0    0    0   0  \n",
       "4      0    0  0   0    0    0    0    0    0   0  \n",
       "..   ...  ... ..  ..  ...  ...  ...  ...  ...  ..  \n",
       "395    0    0  0   0    0    0    0    0    0   0  \n",
       "396    0    0  0   0    0    0    0    0    0   0  \n",
       "397    0    0  0   0    0    0    0    0    0   0  \n",
       "398    0    0  0   0    0    0    0    0    0   0  \n",
       "399    0    0  0   0    0    0    0    0    0   0  \n",
       "\n",
       "[400 rows x 220 columns]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nbtschematic import SchematicFile\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# create python dataframe\n",
    "df = pd.DataFrame(0, index=np.arange(400), columns=[\"label\"])\n",
    "\n",
    "# read all the file\n",
    "ancient_path = '../data/ancient/'\n",
    "modern_path = '../data/modern/'\n",
    "row_index = 0\n",
    "\n",
    "# for ancient building\n",
    "for filename in os.listdir(ancient_path):\n",
    "    if \".schematic\" not in filename:\n",
    "        continue\n",
    "    \n",
    "    sf = SchematicFile.load(ancient_path + filename)\n",
    "    \n",
    "    X = sf.blocks.shape[0]\n",
    "    Y = sf.blocks.shape[1]\n",
    "    Z = sf.blocks.shape[2]\n",
    "    \n",
    "    # counting block\n",
    "    block_record = {}\n",
    "\n",
    "    for i in range(X):\n",
    "        for j in range(Y):\n",
    "            for k in range(Z):\n",
    "                block_id = sf.blocks[i, j, k]\n",
    "                if block_id in block_record.keys():\n",
    "                    block_record[block_id] += 1\n",
    "                else:\n",
    "                    block_record[block_id] = 1\n",
    "    \n",
    "    # insert to dataframe\n",
    "    col_num = len(df.columns)\n",
    "    row_num = 400\n",
    "    \n",
    "    # check whether we need new column\n",
    "    for block_id in block_record:\n",
    "        df.loc[row_index, \"label\"] = 0 #0 represent ancient, 1 represent modern\n",
    "        \n",
    "        block_id = int(block_id)\n",
    "        \n",
    "        if block_id in df.columns:\n",
    "            df.loc[row_index, block_id] = int(block_record[block_id])\n",
    "        else:\n",
    "            df.insert(col_num, block_id, [0 for i in range(row_num)])\n",
    "            col_num += 1\n",
    "            df.loc[row_index, block_id] = int(block_record[block_id])\n",
    "    \n",
    "    row_index += 1\n",
    "    \n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "ca36a7ea-4452-4b40-a2b6-51a5e5fff22e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for modern building\n",
    "for filename in os.listdir(modern_path):\n",
    "    if \".schematic\" not in filename:\n",
    "        continue\n",
    "    \n",
    "    sf = SchematicFile.load(modern_path + filename)\n",
    "    \n",
    "    X = sf.blocks.shape[0]\n",
    "    Y = sf.blocks.shape[1]\n",
    "    Z = sf.blocks.shape[2]\n",
    "    \n",
    "    # counting block\n",
    "    block_record = {}\n",
    "\n",
    "    for i in range(X):\n",
    "        for j in range(Y):\n",
    "            for k in range(Z):\n",
    "                block_id = sf.blocks[i, j, k]\n",
    "                if block_id in block_record.keys():\n",
    "                    block_record[block_id] += 1\n",
    "                else:\n",
    "                    block_record[block_id] = 1\n",
    "    \n",
    "    # insert to dataframe\n",
    "    col_num = len(df.columns)\n",
    "    row_num = 400\n",
    "    \n",
    "    # check whether we need new column\n",
    "    for block_id in block_record:\n",
    "        df.loc[row_index, \"label\"] = 1 #0 represent ancient, 1 represent modern\n",
    "        \n",
    "        block_id = int(block_id)\n",
    "        \n",
    "        if block_id in df.columns:\n",
    "            df.loc[row_index, block_id] = int(block_record[block_id])\n",
    "        else:\n",
    "            df.insert(col_num, block_id, [0 for i in range(row_num)])\n",
    "            col_num += 1\n",
    "            df.loc[row_index, block_id] = int(block_record[block_id])\n",
    "    \n",
    "    row_index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "aa182aca-e0e6-4c69-9efe-f12202f16c8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>7</th>\n",
       "      <th>1</th>\n",
       "      <th>4</th>\n",
       "      <th>98</th>\n",
       "      <th>0</th>\n",
       "      <th>3</th>\n",
       "      <th>-48</th>\n",
       "      <th>5</th>\n",
       "      <th>44</th>\n",
       "      <th>...</th>\n",
       "      <th>-31</th>\n",
       "      <th>-15</th>\n",
       "      <th>-35</th>\n",
       "      <th>-11</th>\n",
       "      <th>-7</th>\n",
       "      <th>-8</th>\n",
       "      <th>-19</th>\n",
       "      <th>-16</th>\n",
       "      <th>-1</th>\n",
       "      <th>-14</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>17667</td>\n",
       "      <td>66956</td>\n",
       "      <td>19754</td>\n",
       "      <td>59458</td>\n",
       "      <td>330777</td>\n",
       "      <td>23900</td>\n",
       "      <td>1246</td>\n",
       "      <td>3360</td>\n",
       "      <td>589</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11238</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>257</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>728</td>\n",
       "      <td>50593</td>\n",
       "      <td>26487</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>117</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10607</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>180</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5586</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>544</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>762</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50346</td>\n",
       "      <td>14103</td>\n",
       "      <td>0</td>\n",
       "      <td>684</td>\n",
       "      <td>196</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11153</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1311</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>37</td>\n",
       "      <td>144</td>\n",
       "      <td>83</td>\n",
       "      <td>32485</td>\n",
       "      <td>16641</td>\n",
       "      <td>0</td>\n",
       "      <td>967</td>\n",
       "      <td>381</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4804</td>\n",
       "      <td>0</td>\n",
       "      <td>197</td>\n",
       "      <td>119982</td>\n",
       "      <td>6201</td>\n",
       "      <td>0</td>\n",
       "      <td>678</td>\n",
       "      <td>23</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2217</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>29441</td>\n",
       "      <td>9046</td>\n",
       "      <td>0</td>\n",
       "      <td>995</td>\n",
       "      <td>1119</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows × 243 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     label      7      1      4     98       0      3   -48     5    44  ...  \\\n",
       "0        0  17667  66956  19754  59458  330777  23900  1246  3360   589  ...   \n",
       "1        0      0      0      0      0   11238      0     0   257     0  ...   \n",
       "2        0      0      0      0    728   50593  26487     0     0   117  ...   \n",
       "3        0      0      6      0      0   10607      0     0     0    21  ...   \n",
       "4        0      0    180      0      0    5586      0     0   544     0  ...   \n",
       "..     ...    ...    ...    ...    ...     ...    ...   ...   ...   ...  ...   \n",
       "395      1     12    762      0      0   50346  14103     0   684   196  ...   \n",
       "396      1      0      0      0      0   11153      0     0     0  1311  ...   \n",
       "397      1      0     37    144     83   32485  16641     0   967   381  ...   \n",
       "398      1      0   4804      0    197  119982   6201     0   678    23  ...   \n",
       "399      1      0   2217      0      0   29441   9046     0   995  1119  ...   \n",
       "\n",
       "     -31  -15  -35  -11  -7  -8  -19  -16  -1  -14  \n",
       "0      0    0    0    0   0   0    0    0   0    0  \n",
       "1      0    0    0    0   0   0    0    0   0    0  \n",
       "2      0    0    0    0   0   0    0    0   0    0  \n",
       "3      0    0    0    0   0   0    0    0   0    0  \n",
       "4      0    0    0    0   0   0    0    0   0    0  \n",
       "..   ...  ...  ...  ...  ..  ..  ...  ...  ..  ...  \n",
       "395    0    0    0    0   0   0    0    0   0    0  \n",
       "396    0    0    0    0   0   0    0    0   0    0  \n",
       "397    0    0    0    0   0   0    0    0   0    0  \n",
       "398    0    0    0    0   0   0    0    0   0    0  \n",
       "399    0    0    0    0   0   0    0    0   0    0  \n",
       "\n",
       "[400 rows x 243 columns]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36a3a140-c057-424f-b5b7-5a8ff5706e53",
   "metadata": {},
   "source": [
    "### Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "6c148ea1-cb3a-4922-a898-9d0393e22c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 計算哪一種建材對於兩個 label 的差值最大，造成最大的影響\n",
    "D = {}\n",
    "\n",
    "for col in df.columns:\n",
    "    label0_mean = 0\n",
    "    for index_of_label0 in range(200):\n",
    "        label0_mean += df.loc[index_of_label0, col]\n",
    "    label0_mean = label0_mean / 200\n",
    "    \n",
    "    label1_mean = 0\n",
    "    for index_of_label1 in range(200, 400):\n",
    "        label1_mean += df.loc[index_of_label1, col]\n",
    "    label1_mean = label1_mean / 200\n",
    "    \n",
    "    D[col] = abs(label0_mean - label1_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "6bb4e542-78a9-4e25-b4ab-6425f8b1cf6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "\n",
    "# Plot the data distribution by value count of their labels (targets)\n",
    "def beautiful_plot(X, Y, x_label, y_label, title):\n",
    "    x = np.arange(len(X))\n",
    "    y = Y\n",
    "    \n",
    "    plt.figure(figsize=(10,10))\n",
    "    cmap = cm.jet(np.linspace(0, 1, len(X)))\n",
    "    plt.barh(x, y, edgecolor = 'gray', alpha=0.6, color=cmap)\n",
    "    plt.yticks(x, X)\n",
    "    plt.xlabel(x_label)\n",
    "    plt.ylabel(y_label)\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "\n",
    "s = sorted(D.items(), key=lambda item: item[1], reverse=True)[:10]\n",
    "x_list = [k for k, _ in s]\n",
    "y_list = [v for _, v in s]\n",
    "beautiful_plot(x_list, y_list, 'differ', 'Feature', 'Top 10 Features')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d099fdc6-0310-449a-982b-26b0f28ddbae",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "4162a881-50f4-485b-90e2-484769cf2fd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>7</th>\n",
       "      <th>1</th>\n",
       "      <th>4</th>\n",
       "      <th>98</th>\n",
       "      <th>3</th>\n",
       "      <th>-48</th>\n",
       "      <th>5</th>\n",
       "      <th>44</th>\n",
       "      <th>-63</th>\n",
       "      <th>109</th>\n",
       "      <th>...</th>\n",
       "      <th>-31</th>\n",
       "      <th>-15</th>\n",
       "      <th>-35</th>\n",
       "      <th>-11</th>\n",
       "      <th>-7</th>\n",
       "      <th>-8</th>\n",
       "      <th>-19</th>\n",
       "      <th>-16</th>\n",
       "      <th>-1</th>\n",
       "      <th>-14</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>276</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1287</td>\n",
       "      <td>56973</td>\n",
       "      <td>0</td>\n",
       "      <td>330</td>\n",
       "      <td>618</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>271</td>\n",
       "      <td>2548</td>\n",
       "      <td>4538</td>\n",
       "      <td>14092</td>\n",
       "      <td>0</td>\n",
       "      <td>3485</td>\n",
       "      <td>1597</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>979</td>\n",
       "      <td>256</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>649</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>77</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>70</td>\n",
       "      <td>149</td>\n",
       "      <td>0</td>\n",
       "      <td>1219</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>86</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>0</td>\n",
       "      <td>468</td>\n",
       "      <td>0</td>\n",
       "      <td>884</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>220</td>\n",
       "      <td>87</td>\n",
       "      <td>0</td>\n",
       "      <td>126</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>19</td>\n",
       "      <td>101</td>\n",
       "      <td>0</td>\n",
       "      <td>197</td>\n",
       "      <td>476</td>\n",
       "      <td>4</td>\n",
       "      <td>119</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>2</td>\n",
       "      <td>8062</td>\n",
       "      <td>661</td>\n",
       "      <td>962</td>\n",
       "      <td>4697</td>\n",
       "      <td>0</td>\n",
       "      <td>336</td>\n",
       "      <td>768</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>118</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows × 241 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      7     1     4     98     3    -48    5     44   -63    109  ...  -31   \\\n",
       "276     0     0     0  1287  56973     0   330   618     2     0  ...     0   \n",
       "5       0   271  2548  4538  14092     0  3485  1597     0     0  ...     0   \n",
       "309     0     0     0     0      0     0   979   256     0     0  ...     0   \n",
       "152     0     0    27   649      0     0     0    12     0    77  ...     0   \n",
       "52      0     0     0    70    149     0  1219    13     0     6  ...     0   \n",
       "..    ...   ...   ...   ...    ...   ...   ...   ...   ...   ...  ...   ...   \n",
       "11      0     0     0     0      0     0     0    86     0     0  ...     0   \n",
       "114     0   468     0   884      0     0   220    87     0   126  ...     0   \n",
       "47      0     0    11    19    101     0   197   476     4   119  ...     0   \n",
       "155     2  8062   661   962   4697     0   336   768     0    16  ...     0   \n",
       "80      0     0     0     0      0     0     0   118     0     0  ...     0   \n",
       "\n",
       "     -15   -35   -11   -7    -8    -19   -16   -1    -14   \n",
       "276     0     0     0     0     0     0     0     0     0  \n",
       "5       0     0     0     0     0     0     0     0     0  \n",
       "309     0     0     0     0     0     0     0     0     0  \n",
       "152     0     0     0     0     0     0     0     0     0  \n",
       "52      0     0     0     0     0     0     0     0     0  \n",
       "..    ...   ...   ...   ...   ...   ...   ...   ...   ...  \n",
       "11      0     0     0     0     0     0     0     0     0  \n",
       "114     0     0     0     0     0     0     0     0     0  \n",
       "47      0     0     0     0     0     0     0     0     0  \n",
       "155     0     0     0     0     0     0     0     0     0  \n",
       "80      0     0     0     0     0     0     0     0     0  \n",
       "\n",
       "[400 rows x 241 columns]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.utils import shuffle\n",
    "\n",
    "# shuffle the data\n",
    "sample_df = df.copy()\n",
    "sample_df = shuffle(sample_df)\n",
    "target = np.array(sample_df[\"label\"])\n",
    "sample_df = sample_df.drop(\"label\", 1)\n",
    "\n",
    "# block id 0 represent air block, we are not going to consider about it\n",
    "sample_df = sample_df.drop(0, 1)\n",
    "\n",
    "sample_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "034278b1-000d-4ecb-b8ee-cb81cbc60bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "from torch.autograd import Variable\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# traing-test-split 7:3\n",
    "training_sample, testing_sample, training_target, testing_target = train_test_split(sample_df, target, test_size = 0.3) \n",
    "\n",
    "# transfer to numpy array\n",
    "x_training_sample = training_sample.to_numpy()\n",
    "x_testing_sample = testing_sample.to_numpy()\n",
    "\n",
    "# to pytorch numpy\n",
    "T_training_sample = torch.FloatTensor(x_training_sample)\n",
    "T_training_target = torch.LongTensor(training_target).type(torch.LongTensor)\n",
    "\n",
    "T_testing_sample = torch.FloatTensor(x_testing_sample)\n",
    "T_testing_target = torch.LongTensor(testing_target).type(torch.LongTensor)\n",
    "\n",
    "# Pytorch train and test sets\n",
    "train = torch.utils.data.TensorDataset(T_training_sample, T_training_target)\n",
    "test = torch.utils.data.TensorDataset(T_testing_sample, T_testing_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79399085-50e5-4b07-9167-722a71013f89",
   "metadata": {},
   "source": [
    "### Model Construction 1 : ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "33d6e523-9b10-4094-8f1c-1c93e0d1ba64",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ANNModel(nn.Module):\n",
    "    def __init__(self, input_features, hidden_layer1, output_features):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(input_features, hidden_layer1) \n",
    "        self.Sigmoid1 = nn.Sigmoid()\n",
    "        self.fc2 = nn.Linear(hidden_layer1, output_features)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.Sigmoid1(out)\n",
    "        out = self.fc2(out)\n",
    "\n",
    "        return out\n",
    "    \n",
    "\n",
    "input_feature = len(sample_df.columns)\n",
    "hidden_layer1 = 500\n",
    "output_features = 2 # number of type of target\n",
    "\n",
    "# Create ANN\n",
    "model = ANNModel(input_feature, hidden_layer1, output_features)\n",
    "\n",
    "# Cross Entropy Loss \n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68236a63-266a-44d6-b1e4-bf8595485e5d",
   "metadata": {},
   "source": [
    "### Model Training 1 : ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "9e3229c4-86b8-4c7f-a629-9e94f9df2b76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  0  loss: 0.74800700\n",
      "Accuracy: 0.6833333333333333\n",
      "epoch:  1  loss: 0.46501836\n",
      "Accuracy: 0.8166666666666667\n",
      "epoch:  2  loss: 0.36506650\n",
      "Accuracy: 0.825\n",
      "epoch:  3  loss: 0.33324063\n",
      "Accuracy: 0.8583333333333333\n",
      "epoch:  4  loss: 0.22894675\n",
      "Accuracy: 0.875\n",
      "epoch:  5  loss: 0.21766052\n",
      "Accuracy: 0.8333333333333334\n",
      "epoch:  6  loss: 0.24255709\n",
      "Accuracy: 0.8416666666666667\n",
      "epoch:  7  loss: 0.21729237\n",
      "Accuracy: 0.8833333333333333\n",
      "epoch:  8  loss: 0.18342070\n",
      "Accuracy: 0.9\n",
      "epoch:  9  loss: 0.17190744\n",
      "Accuracy: 0.8833333333333333\n",
      "epoch: 10  loss: 0.17218280\n",
      "Accuracy: 0.8833333333333333\n",
      "epoch: 11  loss: 0.17542180\n",
      "Accuracy: 0.875\n",
      "epoch: 12  loss: 0.16869625\n",
      "Accuracy: 0.8833333333333333\n",
      "epoch: 13  loss: 0.15569204\n",
      "Accuracy: 0.9\n",
      "epoch: 14  loss: 0.14251393\n",
      "Accuracy: 0.9\n",
      "epoch: 15  loss: 0.13628830\n",
      "Accuracy: 0.9083333333333333\n",
      "epoch: 16  loss: 0.13809982\n",
      "Accuracy: 0.9083333333333333\n",
      "epoch: 17  loss: 0.13640667\n",
      "Accuracy: 0.9083333333333333\n",
      "epoch: 18  loss: 0.12949720\n",
      "Accuracy: 0.9\n",
      "epoch: 19  loss: 0.12026162\n",
      "Accuracy: 0.9\n",
      "epoch: 20  loss: 0.11550203\n",
      "Accuracy: 0.9166666666666666\n",
      "epoch: 21  loss: 0.11444317\n",
      "Accuracy: 0.925\n",
      "epoch: 22  loss: 0.11373176\n",
      "Accuracy: 0.9166666666666666\n",
      "epoch: 23  loss: 0.10871541\n",
      "Accuracy: 0.9166666666666666\n",
      "epoch: 24  loss: 0.09985280\n",
      "Accuracy: 0.9083333333333333\n",
      "epoch: 25  loss: 0.09546737\n",
      "Accuracy: 0.9\n",
      "epoch: 26  loss: 0.09171422\n",
      "Accuracy: 0.9\n",
      "epoch: 27  loss: 0.09210414\n",
      "Accuracy: 0.9\n",
      "epoch: 28  loss: 0.08972469\n",
      "Accuracy: 0.9166666666666666\n",
      "epoch: 29  loss: 0.08429547\n",
      "Accuracy: 0.9166666666666666\n",
      "epoch: 30  loss: 0.08295508\n",
      "Accuracy: 0.9166666666666666\n",
      "epoch: 31  loss: 0.08115753\n",
      "Accuracy: 0.9083333333333333\n",
      "epoch: 32  loss: 0.07955444\n",
      "Accuracy: 0.9083333333333333\n",
      "epoch: 33  loss: 0.07591832\n",
      "Accuracy: 0.9083333333333333\n",
      "epoch: 34  loss: 0.07326233\n",
      "Accuracy: 0.9166666666666666\n",
      "epoch: 35  loss: 0.06935725\n",
      "Accuracy: 0.9166666666666666\n",
      "epoch: 36  loss: 0.06690840\n",
      "Accuracy: 0.9083333333333333\n",
      "epoch: 37  loss: 0.06476405\n",
      "Accuracy: 0.9083333333333333\n",
      "epoch: 38  loss: 0.06451941\n",
      "Accuracy: 0.9083333333333333\n",
      "epoch: 39  loss: 0.06184911\n",
      "Accuracy: 0.9083333333333333\n",
      "epoch: 40  loss: 0.06209280\n",
      "Accuracy: 0.9083333333333333\n",
      "epoch: 41  loss: 0.06135118\n",
      "Accuracy: 0.9083333333333333\n",
      "epoch: 42  loss: 0.05952155\n",
      "Accuracy: 0.9166666666666666\n",
      "epoch: 43  loss: 0.05868780\n",
      "Accuracy: 0.9083333333333333\n",
      "epoch: 44  loss: 0.05667363\n",
      "Accuracy: 0.9083333333333333\n",
      "epoch: 45  loss: 0.05469085\n",
      "Accuracy: 0.9083333333333333\n",
      "epoch: 46  loss: 0.05340511\n",
      "Accuracy: 0.9\n",
      "epoch: 47  loss: 0.05373902\n",
      "Accuracy: 0.9083333333333333\n",
      "epoch: 48  loss: 0.05473054\n",
      "Accuracy: 0.9083333333333333\n",
      "epoch: 49  loss: 0.05292149\n",
      "Accuracy: 0.9083333333333333\n",
      "epoch: 50  loss: 0.05164574\n",
      "Accuracy: 0.9083333333333333\n",
      "epoch: 51  loss: 0.05137026\n",
      "Accuracy: 0.9083333333333333\n",
      "epoch: 52  loss: 0.05024688\n",
      "Accuracy: 0.9083333333333333\n",
      "epoch: 53  loss: 0.04885007\n",
      "Accuracy: 0.9166666666666666\n",
      "epoch: 54  loss: 0.04768863\n",
      "Accuracy: 0.9166666666666666\n",
      "epoch: 55  loss: 0.04644696\n",
      "Accuracy: 0.9166666666666666\n",
      "epoch: 56  loss: 0.04591121\n",
      "Accuracy: 0.9166666666666666\n",
      "epoch: 57  loss: 0.04407760\n",
      "Accuracy: 0.925\n",
      "epoch: 58  loss: 0.04379759\n",
      "Accuracy: 0.925\n",
      "epoch: 59  loss: 0.04315354\n",
      "Accuracy: 0.9166666666666666\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score, recall_score, precision_score\n",
    "\n",
    "# ANN model training\n",
    "count = 0\n",
    "loss_list = []\n",
    "iteration_list = []\n",
    "accuracy_list = []\n",
    "epochs = 60\n",
    "\n",
    "for i in range(epochs):\n",
    "    pred = model.forward(T_training_sample)\n",
    "    \n",
    "    optimizer.zero_grad() # Clear gradients\n",
    "    loss = criterion(pred, T_training_target)\n",
    "    loss_list.append(loss)\n",
    "    loss.backward() # Calculating gradients\n",
    "    optimizer.step() # Update parameters\n",
    "    \n",
    "\n",
    "    print(f'epoch: {i:2}  loss: {loss.item():10.8f}')\n",
    "    preds = []\n",
    "    with torch.no_grad():\n",
    "        for val in T_testing_sample:\n",
    "            y_hat = model.forward(val)\n",
    "            preds.append(y_hat.argmax().item())\n",
    "    acc = accuracy_score(testing_target, preds)\n",
    "    print(\"Accuracy: {}\".format(acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05a91a0d-fb73-49e2-98a6-76951097f19e",
   "metadata": {},
   "source": [
    "### Result Print : ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "2e73f83a-ee1e-416d-9bb9-e10d17f47f6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix: \n",
      "[[51  5]\n",
      " [ 5 59]]\n",
      "+--------------------+--------------------+--------------------+\n",
      "|      Accuracy      |       Recall       |     Precision      |\n",
      "+--------------------+--------------------+--------------------+\n",
      "| 0.9166666666666666 | 0.9162946428571428 | 0.9162946428571428 |\n",
      "+--------------------+--------------------+--------------------+\n"
     ]
    }
   ],
   "source": [
    "from prettytable import PrettyTable\n",
    "\n",
    "# Predict the result with our model\n",
    "preds = []\n",
    "with torch.no_grad():\n",
    "    for val in T_testing_sample:\n",
    "        y_hat = model.forward(val)\n",
    "        preds.append(y_hat.argmax().item())\n",
    "        \n",
    "acc = accuracy_score(testing_target, preds)\n",
    "cm = confusion_matrix(testing_target, preds)\n",
    "rc = recall_score(testing_target, preds, average='macro')\n",
    "pcs = precision_score(testing_target, preds, average='macro')\n",
    "\n",
    "# print confision matrix seperately because it is too big\n",
    "print(\"Confusion Matrix: \")\n",
    "print(cm)\n",
    "\n",
    "\n",
    "# print table\n",
    "x = PrettyTable()\n",
    "\n",
    "x.field_names = [\"Accuracy\", \"Recall\", \"Precision\"]\n",
    "x.add_row([acc, rc, pcs])\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1dde046-567a-4263-a733-f0b4c0328e17",
   "metadata": {},
   "source": [
    "### Model Construction : Decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "669c4597-bf87-492b-bbc5-c01731da8337",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "def decision_tree_clf(training_sample, training_target, testing_sample, testing_target):\n",
    "    clf = DecisionTreeClassifier()\n",
    "    \n",
    "    predict_list = []\n",
    "    \n",
    "    clf.fit(training_sample, training_target)\n",
    "    predict_list = clf.predict(testing_sample)\n",
    "    \n",
    "    result_list = []\n",
    "    result_list.append(confusion_matrix(testing_target, predict_list))\n",
    "    result_list.append(accuracy_score(testing_target, predict_list))\n",
    "    result_list.append(recall_score(testing_target, predict_list, average='macro'))\n",
    "    result_list.append(precision_score(testing_target, predict_list, average='macro'))\n",
    "    return result_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a40a19f-4cc6-4fa7-a7d8-ca7a92a4ae5b",
   "metadata": {},
   "source": [
    "### Result Print : Decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "94cf8bde-cf58-4c18-8cc1-a218d7d141b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+--------------------+--------------------+--------------------+\n",
      "| Confusion Matrix |      Accuracy      |       Recall       |     Precision      |\n",
      "+------------------+--------------------+--------------------+--------------------+\n",
      "|     [[47  9]     | 0.8166666666666667 | 0.8180803571428572 | 0.8166666666666667 |\n",
      "|     [13 51]]     |                    |                    |                    |\n",
      "+------------------+--------------------+--------------------+--------------------+\n"
     ]
    }
   ],
   "source": [
    "result = decision_tree_clf(training_sample, training_target, testing_sample, testing_target)\n",
    "\n",
    "x = PrettyTable()\n",
    "\n",
    "x.field_names = [\"Confusion Matrix\", \"Accuracy\", \"Recall\", \"Precision\"]\n",
    "x.add_row([result[0], result[1], result[2], result[3]])\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d399bb96-b21f-4182-8ffa-ed6db7cea15f",
   "metadata": {},
   "source": [
    "### Model Construction 3 : Quantum ML model with Variational classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "15cb699d-934b-4899-a457-a2cbdf118bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# relabeling data\n",
    "\n",
    "quantum_df = df.copy()\n",
    "quantum_df = shuffle(quantum_df)\n",
    "\n",
    "for index, row in quantum_df.iterrows():\n",
    "    if quantum_df.loc[index, 'label'] == 0:\n",
    "        quantum_df.loc[index, 'label'] = -1\n",
    "        \n",
    "target = np.array(quantum_df[\"label\"])\n",
    "quantum_df = quantum_df.drop(\"label\", 1)\n",
    "\n",
    "# block id 0 represent air block, we are not going to consider about it\n",
    "quantum_df = quantum_df.drop(0, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "73bcb189-2cfb-4729-a784-c1525e85ceaf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pennylane as qml\n",
    "from pennylane import numpy as qnp\n",
    "from pennylane.optimize import NesterovMomentumOptimizer\n",
    "\n",
    "dev = qml.device(\"default.qubit\", wires=4)\n",
    "\n",
    "def get_angles(x):\n",
    "\n",
    "    beta0 = 2 * qnp.arcsin(qnp.sqrt(x[1] ** 2) / qnp.sqrt(x[0] ** 2 + x[1] ** 2 + 1e-12))\n",
    "    beta1 = 2 * qnp.arcsin(qnp.sqrt(x[3] ** 2) / qnp.sqrt(x[2] ** 2 + x[3] ** 2 + 1e-12))\n",
    "    beta2 = 2 * qnp.arcsin(\n",
    "        qnp.sqrt(x[2] ** 2 + x[3] ** 2)\n",
    "        / qnp.sqrt(x[0] ** 2 + x[1] ** 2 + x[2] ** 2 + x[3] ** 2)\n",
    "    )\n",
    "\n",
    "    return qnp.array([beta2, -beta1 / 2, beta1 / 2, -beta0 / 2, beta0 / 2])\n",
    "\n",
    "\n",
    "def statepreparation(a):\n",
    "    qml.RY(a[0], wires=0)\n",
    "\n",
    "    qml.CNOT(wires=[0, 1])\n",
    "    qml.RY(a[1], wires=1)\n",
    "    qml.CNOT(wires=[0, 1])\n",
    "    qml.RY(a[2], wires=1)\n",
    "\n",
    "    qml.PauliX(wires=0)\n",
    "    qml.CNOT(wires=[0, 1])\n",
    "    qml.RY(a[3], wires=1)\n",
    "    qml.CNOT(wires=[0, 1])\n",
    "    qml.RY(a[4], wires=1)\n",
    "    qml.PauliX(wires=0)\n",
    "\n",
    "def layer(W):\n",
    "    qml.Rot(W[0, 0], W[0, 1], W[0, 2], wires=0)\n",
    "    qml.Rot(W[1, 0], W[1, 1], W[1, 2], wires=1)\n",
    "    qml.CNOT(wires=[0, 1])\n",
    "\n",
    "@qml.qnode(dev)\n",
    "def circuit(weights, angles):\n",
    "    statepreparation(angles)\n",
    "\n",
    "    for W in weights:\n",
    "        layer(W)\n",
    "\n",
    "    return qml.expval(qml.PauliZ(0))\n",
    "\n",
    "\n",
    "def variational_classifier(weights, bias, angles):\n",
    "    return circuit(weights, angles) + bias\n",
    "\n",
    "def square_loss(labels, predictions):\n",
    "    loss = 0\n",
    "    for l, p in zip(labels, predictions):\n",
    "        loss = loss + (l - p) ** 2\n",
    "\n",
    "    loss = loss / len(labels)\n",
    "    return loss\n",
    "\n",
    "def accuracy(labels, predictions):\n",
    "\n",
    "    loss = 0\n",
    "    for l, p in zip(labels, predictions):\n",
    "        if abs(l - p) < 1e-5:\n",
    "            loss = loss + 1\n",
    "    loss = loss / len(labels)\n",
    "\n",
    "    return loss\n",
    "\n",
    "def cost(weights, bias, features, labels):\n",
    "    predictions = [variational_classifier(weights, bias, f) for f in features]\n",
    "    return square_loss(labels, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "a26970d9-09dc-40a1-a30f-9ad954336a93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(400, 2)\n",
      "First X sample (original)  : [0 0]\n",
      "First X sample (padded)    : [0.  0.  0.3 0. ]\n",
      "First X sample (normalized): [0. 0. 1. 0.]\n",
      "First features sample      : [ 3.14159265 -0.          0.         -0.          0.        ]\n"
     ]
    }
   ],
   "source": [
    "X = qnp.array(np.transpose(np.array([quantum_df[24].to_numpy(), quantum_df[1].to_numpy()])))\n",
    "print(X.shape)\n",
    "print(\"First X sample (original)  :\", X[0])\n",
    "\n",
    "# pad the vectors to size 2^2 with constant values\n",
    "padding = 0.3 * qnp.ones((len(X), 1))\n",
    "X_pad = qnp.c_[qnp.c_[X, padding], qnp.zeros((len(X), 1))]\n",
    "print(\"First X sample (padded)    :\", X_pad[0])\n",
    "\n",
    "# normalize each input\n",
    "normalization = qnp.sqrt(qnp.sum(X_pad ** 2, -1))\n",
    "X_norm = (X_pad.T / normalization).T\n",
    "print(\"First X sample (normalized):\", X_norm[0])\n",
    "\n",
    "# angles for state preparation are new features\n",
    "features = qnp.array([get_angles(x) for x in X_norm], requires_grad=False)\n",
    "print(\"First features sample      :\", features[0])\n",
    "\n",
    "Y = qnp.array(target)\n",
    "\n",
    "qnp.random.seed(0)\n",
    "num_data = len(Y)\n",
    "num_train = int(0.75 * num_data)\n",
    "index = qnp.random.permutation(range(num_data))\n",
    "feats_train = features[index[:num_train]]\n",
    "Y_train = Y[index[:num_train]]\n",
    "feats_val = features[index[num_train:]]\n",
    "Y_val = Y[index[num_train:]]\n",
    "\n",
    "# We need these later for plotting\n",
    "X_train = X[index[:num_train]]\n",
    "X_val = X[index[num_train:]]\n",
    "\n",
    "num_qubits = 2\n",
    "num_layers = 6\n",
    "\n",
    "weights_init = 0.01 * qnp.random.randn(num_layers, num_qubits, 3, requires_grad=True)\n",
    "bias_init = qnp.array(0.0, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "a86fb8b5-e737-4d5c-a6d8-bbdc0a466170",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter:     1 | Cost: 1.9798902 | Acc validation: 0.3800000 \n",
      "Iter:     2 | Cost: 1.9802027 | Acc validation: 0.3800000 \n",
      "Iter:     3 | Cost: 1.9808419 | Acc validation: 0.3800000 \n",
      "Iter:     4 | Cost: 1.9821547 | Acc validation: 0.3800000 \n",
      "Iter:     5 | Cost: 1.9837573 | Acc validation: 0.3800000 \n",
      "Iter:     6 | Cost: 1.9840513 | Acc validation: 0.3800000 \n",
      "Iter:     7 | Cost: 1.9847077 | Acc validation: 0.3800000 \n",
      "Iter:     8 | Cost: 1.9849009 | Acc validation: 0.3800000 \n",
      "Iter:     9 | Cost: 1.9846667 | Acc validation: 0.3800000 \n",
      "Iter:    10 | Cost: 1.9832899 | Acc validation: 0.3800000 \n",
      "Iter:    11 | Cost: 1.9820562 | Acc validation: 0.3800000 \n",
      "Iter:    12 | Cost: 1.9805666 | Acc validation: 0.3800000 \n",
      "Iter:    13 | Cost: 1.9785107 | Acc validation: 0.3800000 \n",
      "Iter:    14 | Cost: 1.9759750 | Acc validation: 0.3800000 \n",
      "Iter:    15 | Cost: 1.9740930 | Acc validation: 0.3800000 \n",
      "Iter:    16 | Cost: 1.9724391 | Acc validation: 0.3800000 \n",
      "Iter:    17 | Cost: 1.9706454 | Acc validation: 0.3800000 \n",
      "Iter:    18 | Cost: 1.9687262 | Acc validation: 0.3800000 \n",
      "Iter:    19 | Cost: 1.9670222 | Acc validation: 0.3800000 \n",
      "Iter:    20 | Cost: 1.9655191 | Acc validation: 0.3800000 \n",
      "Iter:    21 | Cost: 1.9638924 | Acc validation: 0.3800000 \n",
      "Iter:    22 | Cost: 1.9621489 | Acc validation: 0.3800000 \n",
      "Iter:    23 | Cost: 1.9612136 | Acc validation: 0.3800000 \n",
      "Iter:    24 | Cost: 1.9603854 | Acc validation: 0.3800000 \n",
      "Iter:    25 | Cost: 1.9596513 | Acc validation: 0.3800000 \n",
      "Iter:    26 | Cost: 1.9589983 | Acc validation: 0.3800000 \n",
      "Iter:    27 | Cost: 1.9575219 | Acc validation: 0.3800000 \n",
      "Iter:    28 | Cost: 1.9556544 | Acc validation: 0.3800000 \n",
      "Iter:    29 | Cost: 1.9542667 | Acc validation: 0.3800000 \n",
      "Iter:    30 | Cost: 1.9533193 | Acc validation: 0.3800000 \n",
      "Iter:    31 | Cost: 1.9524691 | Acc validation: 0.3800000 \n",
      "Iter:    32 | Cost: 1.9511738 | Acc validation: 0.3800000 \n",
      "Iter:    33 | Cost: 1.9500147 | Acc validation: 0.3800000 \n",
      "Iter:    34 | Cost: 1.9497160 | Acc validation: 0.3800000 \n",
      "Iter:    35 | Cost: 1.9501812 | Acc validation: 0.3800000 \n",
      "Iter:    36 | Cost: 1.9505838 | Acc validation: 0.3800000 \n",
      "Iter:    37 | Cost: 1.9514640 | Acc validation: 0.3800000 \n",
      "Iter:    38 | Cost: 1.9519951 | Acc validation: 0.3800000 \n",
      "Iter:    39 | Cost: 1.9530226 | Acc validation: 0.3800000 \n",
      "Iter:    40 | Cost: 1.9533440 | Acc validation: 0.3800000 \n",
      "Iter:    41 | Cost: 1.9535833 | Acc validation: 0.3800000 \n",
      "Iter:    42 | Cost: 1.9531488 | Acc validation: 0.3800000 \n",
      "Iter:    43 | Cost: 1.9526773 | Acc validation: 0.3800000 \n",
      "Iter:    44 | Cost: 1.9519315 | Acc validation: 0.3800000 \n",
      "Iter:    45 | Cost: 1.9504893 | Acc validation: 0.3800000 \n",
      "Iter:    46 | Cost: 1.9490911 | Acc validation: 0.3800000 \n",
      "Iter:    47 | Cost: 1.9477256 | Acc validation: 0.3800000 \n",
      "Iter:    48 | Cost: 1.9461535 | Acc validation: 0.3800000 \n",
      "Iter:    49 | Cost: 1.9449642 | Acc validation: 0.3800000 \n",
      "Iter:    50 | Cost: 1.9443029 | Acc validation: 0.3800000 \n",
      "Iter:    51 | Cost: 1.9430324 | Acc validation: 0.3800000 \n",
      "Iter:    52 | Cost: 1.9415113 | Acc validation: 0.3800000 \n",
      "Iter:    53 | Cost: 1.9401314 | Acc validation: 0.3800000 \n",
      "Iter:    54 | Cost: 1.9377371 | Acc validation: 0.3800000 \n",
      "Iter:    55 | Cost: 1.9345337 | Acc validation: 0.3800000 \n",
      "Iter:    56 | Cost: 1.9320682 | Acc validation: 0.3800000 \n",
      "Iter:    57 | Cost: 1.9291428 | Acc validation: 0.3800000 \n",
      "Iter:    58 | Cost: 1.9260582 | Acc validation: 0.3800000 \n",
      "Iter:    59 | Cost: 1.9229643 | Acc validation: 0.3800000 \n",
      "Iter:    60 | Cost: 1.9197010 | Acc validation: 0.3800000 \n"
     ]
    }
   ],
   "source": [
    "opt = NesterovMomentumOptimizer(0.001)\n",
    "batch_size = 5\n",
    "\n",
    "# train the variational classifier\n",
    "weights = weights_init\n",
    "bias = bias_init\n",
    "\n",
    "for it in range(60):\n",
    "    # Update the weights by one optimizer step\n",
    "    batch_index = qnp.random.randint(0, num_train, (batch_size,))\n",
    "    feats_train_batch = feats_train[batch_index]\n",
    "    Y_train_batch = Y_train[batch_index]\n",
    "    weights, bias, _, _ = opt.step(cost, weights, bias, feats_train_batch, Y_train_batch)\n",
    "\n",
    "    # Compute predictions on train and validation set\n",
    "    predictions_train = [qnp.sign(variational_classifier(weights, bias, f)) for f in feats_train]\n",
    "    predictions_val = [qnp.sign(variational_classifier(weights, bias, f)) for f in feats_val]\n",
    "\n",
    "    # Compute accuracy on train and validation set\n",
    "    acc_train = accuracy(Y_train, predictions_train)\n",
    "    acc_val = accuracy(Y_val, predictions_val)\n",
    "\n",
    "    print(\n",
    "        \"Iter: {:5d} | Cost: {:0.7f} | Acc validation: {:0.7f} \"\n",
    "        \"\".format(it + 1, cost(weights, bias, features, Y), acc_val)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df4cc265-0a91-4fb8-ac03-4d5707821ecb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d0e9ba1-d5bb-4029-a9a6-88820eb8e1cc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
